O paper que vou apresentar chama-se "Aegan: replication beyond the client-server model" por Remzi Aksoy e Manos Kapritsos.

Hoje em dia, quando um cliente interage com um servidor, muitas das vezes está a interagir com um serviço replicado. A principal motivação dos autores reside na particularidade de quando estes serviços replicados precisam de interagir com outros serviços externos, como por exemplo num pedido de pagamento numa loja online.

A este tipo de interação os autores nomeiam de nested requests e defendem que até à data do paper não existia nenhum protocolo correto e eficiente que tivesse em conta este tipo de interação.

Porque que nenhum protocolo existente está correto?

São todos baseados no modelo de State Machine Replication, que dá a ilusão ao cliente que está apenas a interagir com uma single correct machine.

Mas nenhum deles tem em conta a mesma abstração para os serviços externos. Vamos ver de seguida mais em detalhe o porque de alguns destes protocolos serem incorretos.

E ineficientes porque?

Estes protocolos requerem que os pedidos sejam todos executados numa ordem pré-definida, ou seja, um pedido só pode ser começado após o anterior ter acabado.

O que resulta em serviços ficarem parados à espera de resposta de outros serviços enquanto podiam processar outro tipo de pedidos.

Vamos agora ver mais em detalhe o porque de alguns protocolos estarem incorretos.
Vamos ter em consideração o mesmo modelo anteriormente apresentado.
Um cliente, um middle service replicado (que representará a loja online) e um backend (que representará o serviço de cartão de crédito). 

Num middle service replicado com Primary-Backup. 

Ok vamos supor que o cliente faz um pedido de pagamento, o serviço primário propaga o pedido para o backend mas depois crasha. Eventualmente o backup torna-se no novo primário, mas infelizmente não consegue repetir a execução do serviço primário.
Mesmo assim vamos supor que consegue repetir a execução do serviço primário. Neste caso, o serviço poderia agora realizar que o item se encontra fora de stock e retornar um erro ao cliente. No entanto, o cliente já foi cobrado pelo item.
Ou então, poderia também mandar outra vez um pedido de pagamento ao serviço externo, resultando em o cliente ser cobrado duas vezes.
O problema com o primary-backup é que o serviço primário faz uma interação externa sem antes assegurar que o pedido foi também propagado para o backup.

Vamos ver agora com o Paxos.
Num middle service replicado com protocolos baseados no Paxos, todas as réplicas executam todos os pedidos, resultando em pedidos duplicados no backend.

OKay muito bem, podemos dizer que os pedidos são iguais portanto é fácil de encontrar duplicados e do backup assim ignorar o seu processamento.

Então vamos supor o seguinte, o cliente envia os mesmos 10 nested requests ao serviço replicado, a replica A envia os 10 para o backend e o backed envia as 10 respostas muito bem. Mas depois da réplica A mandar as 10 respostas ao cliente crasha.
Como é que a replica B pode chegar ao mesmo estado da réplica A? Visto que o seu estado já foi exposto ao cliente?
Se mandar-mos os 10 pedidos, o backed simplesmente vai ignorar os duplicados.
Portanto, o problema mantem-se.

Por fim os autores revem um middle service replicado com execução especulativa.

Muitos dos serviços replicados usam a especulação para executar pedidos antes de haver um consenso entre replicas por motivos de performance.  Por si só, a execução especulativa funciona se o cliente não for exposto a estados inconscitentes provenientes de especulações falhadas.
No entanto, o seu uso neste tipo de interações pode ameaçar a correção do sistema, visto não ter em conta serviços externos.

Resumindo e baralhando, podemos dividir todos estes problemas em 3 tipos.

O primeiro é quando numa interação onde um serviço replicado eventualmente funciona como um cliente replicado. Em vez de cada réplica de cliente enviar a sua própria copia de um pedido, estes deviam ser logicamente tratados como um pedido único mantendo assim a abstração de single correct machine para serviços externos.

O segundo refere o facto de quando uma réplica do middle service recebe uma resposta de um nested request, esta não poder simplesmente acabar a sua execução e mandar a resposta de volta ao cliente. Se o fizer e crashar, as outras réplicas podem não identificar quais foram as respostas. Em vez disso, a réplica deve primeiro garantir que a resposta ao nested request foi recebido pela maioria das réplicas.

Por fim, este tipo de interação nunca pode ser baseada em especulação, visto que se o fizermos podemos expor um estado ao backed service que mais tarde poderá revertido, violando assim a abstração de single correct machine.

Com isto os autores propoem um conjunto de conceitos e técnicas completamente gerais. O middle service poderá ser sincrono ou assincrono, podendo tolerar qualquer tipo de falhas, sejam byzantinas ou não.

Para garantir a propriedade de liveness assumem a existencia de intervalos sincronos durante os quais as mensagens enviadas entre os nós corretos são recebidas e processadas.

O backend pode ou não ser replicado.

Sendo o modelo de falha o seguinte:

Para o sistema se mater vivo, ou seja, conseguir responder aos pedidos do cliente, poderá ter no máximo u numero de falhas em simultaneo. 

E para se manter seguro, ou seja, nao responder incorretamente a pedidos de clientes, poderá ter no máximo r falhas byzantinas e um numero arbirtário de falhas por omissão.

Para a correção, os autores não querem ficar restritos à execução sequencial, devido a mesma ser muito limitativa. Portanto usam uma definição mais genérica, que é a indistinguibilidade, ou seja, um serviço replicado é correto se os seus resultados não se poderem distinguir dos resultados de um serviço não replicado.

Portanto para assegurar a correção, os autores propoem três técnicas que vão encontro dos 3 tipos de problemas apresentados anteriormente, estes são: server-shim, Response-durability e spec-tame.

Server-shim, uma técnica que é posta entre o middle service e o backend.

Quando um middle service faz um pedido, o server-shim autentica o pedido e espera até que haja um quorum correspondente antes de envia-la para o backend.

Depois de enviar para o backend discarda qualquer copia de pedido.

Quando recebe uma resposta do backend, o server-shim faz um broadcast da resposta para todas as réplicas, assegurando que nenhuma se perde na rede, enviando de novo a mensagem caso seja necessário.

Response-durability garante que tanto os pedidos dos clientes como as respostas do backend são registados de forma durável. Ao receber uma resposta de um nested request envia a resposta para todas as outras réplicas e espera até receber u + 1 ACKS.

Spec-tame permite que neste tipo de interações seja possivel usar a especulação mantendo a abstração da single correct machine para todos os backend services. A ideia por trás desta técnica é de não fazer nenhuma interação com o backend até a especulação estar resolvida.

Com estas três têcnicas os autores dizem corrigir os 3 antes definidos e só falta resolver a consistencia entre réplicas sem execuções sequenciais.
Como dito anteriormente, a arquitetura onde as réplicas primeiramente acordam numa ordem de execução e só depois as executam sequencialmente é maioritariamente usada pelos protocolos existentes. O que força que ao middle service a ficar parado enquanto aguarda respostas do backend service.

Para resolver este problema os autores introduzem o conceito de request pipelining . Este conceito permite ao middle service continuar a processar pedidos enquanto os seus nested requests estão a ser processados.
Resumidamente o middle service ira executar requests em sequencia até que os pedidos acabam ou até ser preciso fazer um nested request.
Depois das respostas às nested requests terem chegado, os pedidos que estavam à espera são processados pela ordem da pipeline e não pela ordem de chegada. 

Aqui podemos ver um exemplo do pipeline.
O serviço A vai processando os pedidos em ordem até encontrar um nested request, depois de processar todos os nested requests volta à execução dos pedidos pela mesma ordem do pipeline.









